{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: predict wine rating from description, region, etc.\n",
    "=======================================================\n",
    "\n",
    "I. Questions to answer:\n",
    "-----------------------\n",
    "1. What worlds are the most common in description?\n",
    "2. What worlds are the most common in descriptions of high rating wines?\n",
    "3. What words are the most common in descriptions of low rating wines?\n",
    "4. What words can be found only in one group (high rating / low rating)?\n",
    "5. What words are the most common for each of the grapes?\n",
    "6. Is there correlation between price and rating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libs\n",
    "import pandas as pd\n",
    "import plotly as py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load wines dataset\n",
    "wines_df = pd.read_csv('winemag-data-130k-v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform descriptions to bags of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WINE_STOP_WORDS = [\n",
    "    'wine',\n",
    "    'wines',\n",
    "    'drink',\n",
    "    'drinks',\n",
    "    'flavor',\n",
    "    'flavors',\n",
    "    'aroma',\n",
    "    'aromas',\n",
    "    'note',\n",
    "    'notes',\n",
    "    'good',\n",
    "    'well',\n",
    "    'year',\n",
    "    'years',\n",
    "    'make',\n",
    "    'made',\n",
    "    'nose',\n",
    "    'give',\n",
    "    'gives',\n",
    "    'gived',\n",
    "    'one',\n",
    "    'feel',\n",
    "    'feels',\n",
    "    'also',\n",
    "    'taste',\n",
    "    'testes',\n",
    "    'seem',\n",
    "    'seems',\n",
    "    'last',\n",
    "    'lasts',\n",
    "    'yet', \n",
    "    'finish',\n",
    "    'texture',\n",
    "    'like',\n",
    "    'time',\n",
    "    'almost',\n",
    "    'mouth',\n",
    "    \n",
    "    # words that can be found in all ratings\n",
    "    # interesting that majority of them are some characteristics\n",
    "    # of the wine. apparently it's such a broad description, so it doesn't\n",
    "    # affect overall quality\n",
    "    # All of them are seen in more than 500 wines description\n",
    "    # around 0.4%\n",
    "    'still', \n",
    "    'fine', \n",
    "    'toast', \n",
    "    'noir', \n",
    "    'cherry', \n",
    "    'texture', \n",
    "    'sugar', \n",
    "    'wood', \n",
    "    'black', \n",
    "    'rich', \n",
    "    'brown', \n",
    "    'coffee', \n",
    "    'blackberries', \n",
    "    'citrus', \n",
    "    'big', \n",
    "    'showing', \n",
    "    'overall', \n",
    "    'crushed', \n",
    "    'dark', \n",
    "    'crisp', \n",
    "    'impressive', \n",
    "    'tobacco', \n",
    "    'leather', \n",
    "    'freshness', \n",
    "    'blackberry',\n",
    "    'core', \n",
    "    'pinot', \n",
    "    'intensity', \n",
    "    'currant', \n",
    "    'dried', \n",
    "    'best', \n",
    "    'even', \n",
    "    'minerality', \n",
    "    'new', \n",
    "    'red', \n",
    "    'shows', \n",
    "    'franc', \n",
    "    'full', \n",
    "    'grapes', \n",
    "    '100', \n",
    "    'come', \n",
    "    'dry', \n",
    "    'many', \n",
    "    'keep', \n",
    "    'cinnamon', \n",
    "    'spices', \n",
    "    'first', \n",
    "    'already', \n",
    "    'color', \n",
    "    'sweet', \n",
    "    'powerful', \n",
    "    'least', \n",
    "    'balanced', \n",
    "    'acidity', \n",
    "    'licorice', \n",
    "    'long', \n",
    "    'white', \n",
    "    'syrup', \n",
    "    'opens', \n",
    "    'sauvignon', \n",
    "    'chocolate', \n",
    "    'perfumed', \n",
    "    'delivers', \n",
    "    'hold', \n",
    "    'spice', \n",
    "    'chardonnay', \n",
    "    'vanilla', \n",
    "    'fruits', \n",
    "    'balance', \n",
    "    'tannins', \n",
    "    'palate', \n",
    "    'ripe', \n",
    "    'almost', \n",
    "    'high', \n",
    "    'sense', \n",
    "    'concentration', \n",
    "    'huge', \n",
    "    'end', \n",
    "    'variety', \n",
    "    'vintage', \n",
    "    'oak', \n",
    "    'merlot',\n",
    "    'pure', \n",
    "    'berry', \n",
    "    'finish', \n",
    "    'fruit', \n",
    "    'mouth', \n",
    "    'cabernet', \n",
    "    'structure', \n",
    "    'bodied', \n",
    "    'age', \n",
    "    'green', \n",
    "    'bottle', \n",
    "    'blend'   \n",
    "]\n",
    "\n",
    "def _tokenise(sentense):\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    try:\n",
    "        return word_tokenize(sentense)\n",
    "    except UnicodeDecodeError: \n",
    "        return word_tokenize(sentense.decode('utf-8'))\n",
    "\n",
    "def _clean_tokens(tokens):\n",
    "    \"\"\"\n",
    "    Transform to lowcase\n",
    "    Remove punctuations from words\n",
    "    Filter out words with length less than 2 symbols\n",
    "    \"\"\"\n",
    "    from itertools import chain\n",
    "    \n",
    "    def _clean_token(token):\n",
    "        import re\n",
    "        token = token.lower()\n",
    "        return re.split(r'[^\\w\\s]', token)\n",
    "\n",
    "    tokens = chain(*map(_clean_token, tokens))\n",
    "    MIN_TOKEN_LENGTH = 2\n",
    "    return filter(\n",
    "        lambda t: len(t) >= MIN_TOKEN_LENGTH,\n",
    "        tokens)\n",
    "\n",
    "def _filter_out_stop_words(tokens):\n",
    "    from nltk.corpus import stopwords\n",
    "    import string\n",
    "    stop_list = \\\n",
    "        stopwords.words('english') + \\\n",
    "        list(string.punctuation) + \\\n",
    "        WINE_STOP_WORDS\n",
    "    return filter(\n",
    "            lambda token: token not in stop_list,\n",
    "            tokens)\n",
    "\n",
    "\n",
    "def transfrom_to_bag_of_words(senstense):\n",
    "    \"\"\"\n",
    "    Transform sentense to bag of words using nltk tokeniser\n",
    "    Filter out stop words\n",
    "    \"\"\"\n",
    "    tokens = _tokenise(senstense)\n",
    "    tokens = _clean_tokens(tokens)\n",
    "    return _filter_out_stop_words(tokens)\n",
    "\n",
    "wines_df['description_as_bag_of_words'] = wines_df.apply(\n",
    "    lambda x: transfrom_to_bag_of_words(x.description),\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Train Support Vector Regressor with different C an epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate tf idf\n",
      "(129971, 30810)\n",
      "Select significant features\n",
      "(129971, 521)\n",
      "Scale numerical\n",
      "Binarize categorical features\n",
      "(129971, 2408)\n",
      "Select significant features\n",
      "(129971, 291)\n",
      "Normalize\n",
      "Test C and gamma:0.100000 / 0.100000\n",
      "[CV]  ................................................................\n",
      "[CV] ........................... , score=0.929992613794, total=72.3min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 72.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................... , score=0.929992613794, total=71.2min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 143.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................... , score=0.929990997853, total=70.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 214.3min finished\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-274b176b3d77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mNUMERICAL_FEATURES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mCATEGORICAL_FEATURES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         RESULT_COLUMN)\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0mshow_regresion_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregression_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-274b176b3d77>\u001b[0m in \u001b[0;36mtry_train_svr\u001b[0;34m(df_, text_feature, numerical_features, categorical_features, result)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test C and gamma:%f / %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         accuracy = _train_and_validate_svr(\n\u001b[0;32m--> 150\u001b[0;31m             C, gamma, X, y)\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         regression_results.append(\n",
      "\u001b[0;32m<ipython-input-4-274b176b3d77>\u001b[0m in \u001b[0;36m_train_and_validate_svr\u001b[0;34m(C, gamma, X, y)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# switch of multiprocessing - too slow with 2nd python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         verbose=3)\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mreturn\u001b[0m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_calculate_tf_idf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "def _train_and_validate_svr(\n",
    "        C, gamma, X, y):\n",
    "    \"\"\"\n",
    "    Train svr with given params an\n",
    "    calculate accuracy using cross validation\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    clf = SVC(C=C, gamma=gamma)\n",
    "    NUMBER_OF_CROSS_VAL_TRIES = 3\n",
    "    scores = cross_val_score(\n",
    "        clf, X, y, cv=NUMBER_OF_CROSS_VAL_TRIES,\n",
    "        n_jobs=1, # switch of multiprocessing - too slow with 2nd python\n",
    "        verbose=3)\n",
    "    return \\\n",
    "        clf.fit(X, y), \\\n",
    "        np.mean(scores)\n",
    "\n",
    "def _calculate_tf_idf(df_):\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    print('Calculate tf idf')\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    return vectorizer.fit_transform(\n",
    "        df_.as_matrix())\n",
    "\n",
    "def _scale_numerical_features(df_):\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    print('Scale numerical')\n",
    "    scaler =  MinMaxScaler()\n",
    "    return scaler.fit_transform(\n",
    "        df_.fillna(0).as_matrix())\n",
    "\n",
    "def _binarize_categorical_features(df_):\n",
    "    import numpy as np\n",
    "    from sklearn.feature_extraction import DictVectorizer\n",
    "    print('Binarize categorical features')\n",
    "    vectorizer = DictVectorizer(sparse=False)\n",
    "    # convert dataframe to matrix\n",
    "    D = [\n",
    "        val for index, val in \n",
    "        sorted(\n",
    "            df_.T.to_dict().items(),\n",
    "            key=lambda x: x [0])]\n",
    "    X = vectorizer.fit_transform(D)\n",
    "    X = np.nan_to_num(X)\n",
    "    return X\n",
    "\n",
    "def _prepare_text_feature_for_tf_idf(df_, text_feature):\n",
    "    \"\"\"\n",
    "    Join array to string, so it can be processes by tf idf transformer\n",
    "    Modifies dataframe column inplace\n",
    "    \"\"\"\n",
    "    def _join_array_to_string(arr):\n",
    "        return ' '.join((arr))\n",
    "\n",
    "    new_text_feature = '%s_' % text_feature\n",
    "    df_[new_text_feature] = df_.apply(\n",
    "        lambda x: _join_array_to_string(x[text_feature]),\n",
    "        axis=1)\n",
    "    return new_text_feature\n",
    "\n",
    "def _select_significant_text_features_using_classifier(X, y):\n",
    "    \"\"\"\n",
    "    Use LinearSVC to preselect text features\n",
    "    \"\"\"\n",
    "    # TODO experiment with C\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.feature_selection import SelectFromModel\n",
    "    print('Select significant features')\n",
    "    lc = LinearSVC(\n",
    "        C=0.05,\n",
    "        penalty=\"l1\", \n",
    "        dual=False).fit(X, y)\n",
    "    model = SelectFromModel(lc, prefit=True)\n",
    "    return model.transform(X)\n",
    "\n",
    "def _transform_points_to_class(points):\n",
    "    \"\"\"\n",
    "    Return class number according to points amount\n",
    "    \"\"\"\n",
    "    HIGH_RATING = 94\n",
    "    LOW_RATING = 83\n",
    "    if points < LOW_RATING:\n",
    "        # low rating wines\n",
    "        return 0\n",
    "    if points < HIGH_RATING:\n",
    "        # average wines\n",
    "        return 1\n",
    "    return 2 # exceptional wines\n",
    "\n",
    "def _generate_x_and_y_from_df(\n",
    "        df_, text_feature, numerical_features, categorical_features,\n",
    "        result, normalize_results=True):\n",
    "    \"\"\"\n",
    "    Generate normalised matrix from dataframe\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from scipy import sparse \n",
    "    from sklearn.preprocessing import normalize\n",
    "    # get y\n",
    "    y = df_[result].\\\n",
    "        apply(\n",
    "            _transform_points_to_class).\\\n",
    "        as_matrix()\n",
    "    \n",
    "    # get x\n",
    "    new_text_feature = _prepare_text_feature_for_tf_idf(df_, text_feature)\n",
    "    text_x = _calculate_tf_idf(df_[new_text_feature])\n",
    "    # preselect significant x features\n",
    "    text_x = _select_significant_text_features_using_classifier(\n",
    "        text_x, y)\n",
    "    numerical_features = _scale_numerical_features(df_[numerical_features])\n",
    "    categorical_features = _binarize_categorical_features(df_[categorical_features])\n",
    "    categorical_features = _select_significant_text_features_using_classifier(\n",
    "        categorical_features, y)\n",
    "    X = sparse.hstack(\n",
    "        (\n",
    "            text_x,\n",
    "            sparse.csr_matrix(numerical_features),\n",
    "            sparse.csr_matrix(categorical_features)\n",
    "        ))\n",
    "    if not normalize_results:\n",
    "        return X, y\n",
    "    print('Normalize')\n",
    "    return normalize(X), y\n",
    "\n",
    "def try_train_svr(\n",
    "        df_, text_feature, numerical_features, categorical_features, result):\n",
    "    \"\"\"\n",
    "    Experiment with different types of C and epsilon to train SVR on\n",
    "    given dataset\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    X, y = _generate_x_and_y_from_df(\n",
    "        df_, text_feature, \n",
    "        numerical_features, categorical_features, result)\n",
    "    X = X.todense()\n",
    "\n",
    "    C_s = [\n",
    "        0.1, 1, 10, 100, 1000]\n",
    "    gammas = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "    c_and_gammas = itertools.product(C_s, gammas)\n",
    "\n",
    "    # run regression with different SVR params\n",
    "    regression_results = []\n",
    "    for C, gamma in c_and_gammas:\n",
    "        print('Test C and gamma:%f / %f' % (C, gamma))\n",
    "        accuracy = _train_and_validate_svr(\n",
    "            C, gamma, X, y)\n",
    "        print('Accuracy', accuracy)\n",
    "        regression_results.append(\n",
    "            {\n",
    "                'accuracy': accuracy,\n",
    "                'C': C,\n",
    "                'gamma': gamma\n",
    "            })\n",
    "\n",
    "    regression_results = sorted(\n",
    "           regression_results,\n",
    "           key=lambda res: res['accuracy'],\n",
    "           reversed=True)\n",
    "\n",
    "    # return regression results\n",
    "    return regression_results\n",
    "\n",
    "\n",
    "def show_regresion_results(results):\n",
    "    for result in results[:5]:\n",
    "        print('C', result['C'])\n",
    "        print('gamma', result['gamma'])\n",
    "        print('accuracy', result['accuracy'])\n",
    "       \n",
    "    \n",
    "TEXT_FEATURE = 'description_as_bag_of_words'\n",
    "NUMERICAL_FEATURES = [\n",
    "    'price',\n",
    "    \n",
    "]\n",
    "CATEGORICAL_FEATURES = [\n",
    "    'country',\n",
    "    'variety',\n",
    "    'province',\n",
    "    'region_1'\n",
    "]\n",
    "RESULT_COLUMN = 'points'\n",
    "\n",
    "regression_results = try_train_svr(\n",
    "        wines_df, TEXT_FEATURE, \n",
    "        NUMERICAL_FEATURES, \n",
    "        CATEGORICAL_FEATURES,\n",
    "        RESULT_COLUMN)\n",
    "\n",
    "show_regresion_results(regression_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialise Plotly\n",
    "py.offline.init_notebook_mode()\n",
    "\n",
    "# Helpers for visualising distribution\n",
    "def _get_value_counts_from_series(column, series):\n",
    "    \"\"\"\n",
    "    Return series unique values as x and value counts as y\n",
    "    \"\"\"\n",
    "    # display zeros on graph also\n",
    "    df = series.value_counts().to_frame()\n",
    "    df = df.sort_index()\n",
    "    return df.index.tolist(), df[column].tolist()\n",
    "\n",
    "def _plot_numeric_feature(column, series):\n",
    "    \"\"\"\n",
    "    Helper to display scatter plot \n",
    "    using series index as x and series values as y\n",
    "    \"\"\"\n",
    "    x, y = _get_value_counts_from_series(column, series.fillna(0))\n",
    "    data = py.graph_objs.Scatter(\n",
    "        x=x, y=y)\n",
    "    layout = py.graph_objs.Layout(title=column)\n",
    "    py.offline.iplot({\n",
    "            'data': [data], \n",
    "            'layout': layout})\n",
    "    \n",
    "    \n",
    "def _plot_categorical_featrue(column, series):\n",
    "    \"\"\"\n",
    "    Helper to display bar plot \n",
    "    using series index as x and series values as y\n",
    "    \"\"\"\n",
    "    x, y = _get_value_counts_from_series(column, series.fillna('No data'))\n",
    "    data = py.graph_objs.Bar(\n",
    "        x=x, y=y)\n",
    "    layout = py.graph_objs.Layout(title=column)\n",
    "    py.offline.iplot({\n",
    "            'data': [data], \n",
    "            'layout': layout})\n",
    "\n",
    "    \n",
    "# Visualise distributions for categorical and numerical features\n",
    "CATEGORICAL_FEATURES = [\n",
    "    'country',\n",
    "    'province',\n",
    "    'region_1',\n",
    "    'region_2',\n",
    "    'variety',\n",
    "    'winery'\n",
    "]\n",
    "\n",
    "NUMERICAL_FEATURES = [\n",
    "    'points',\n",
    "    'price'\n",
    "]\n",
    "for column in CATEGORICAL_FEATURES:\n",
    "    _plot_categorical_featrue(column, wines_df[column])\n",
    "    \n",
    "for column in NUMERICAL_FEATURES:\n",
    "    _plot_numeric_feature(column, wines_df[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data cleanliness\n",
    "\n",
    "1. _63 wines_ have no **country**\n",
    "2. _80k_ have no **region 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What worlds are the most and least common in descriptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_words_popularity(\n",
    "        descriptions, include_numbers=False):\n",
    "    \"\"\"\n",
    "    Calculate each words popularity as number of descriptions\n",
    "    where the word can be found\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    from itertools import chain\n",
    "    # remove dublicates from descriptions\n",
    "    descriptions_as_sets = [\n",
    "        set(description)\n",
    "        for description in descriptions.tolist()]\n",
    "    descriptions_flat = chain(*descriptions_as_sets)\n",
    "    if not include_numbers:\n",
    "        descriptions_flat = filter(\n",
    "            lambda w: not w.isdigit(),\n",
    "            descriptions_flat)\n",
    "    word_counts = Counter(descriptions_flat)\n",
    "    return word_counts\n",
    "\n",
    "def plot_words_popularity(word_counts, title):\n",
    "    \"\"\"\n",
    "    Plot words poularity. Expects counter format\n",
    "    \"\"\"\n",
    "    x, y = \\\n",
    "        [c[0] for c in word_counts], \\\n",
    "        [c[1] for c in word_counts]\n",
    "    \n",
    "    data = py.graph_objs.Bar(\n",
    "        x=x, y=y)\n",
    "    layout = py.graph_objs.Layout(title=title)\n",
    "    py.offline.iplot({\n",
    "            'data': [data], \n",
    "            'layout': layout})\n",
    "\n",
    "def show_most_popular_and_less_popular_words(\n",
    "        descriptions, graph_title):\n",
    "    \"\"\"\n",
    "    Show mots and less popular words in passed descriptions\n",
    "    \"\"\"\n",
    "    N_POPULAR = 100\n",
    "    word_counts = calculate_words_popularity(descriptions)\n",
    "    # Show most popular words\n",
    "    plot_words_popularity(\n",
    "        word_counts.most_common(N_POPULAR),\n",
    "        'Most popular words -- %s' % graph_title)\n",
    "    # Show less popular words\n",
    "    plot_words_popularity(\n",
    "        word_counts.most_common()[:-N_POPULAR-1:-1],\n",
    "        'Less popular words -- %s' % graph_title)    \n",
    "\n",
    "show_most_popular_and_less_popular_words(\n",
    "    wines_df.description_as_bag_of_words,\n",
    "    'Total')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# What worlds are the most common in high rated wines?\n",
    "1. What is the average rate?\n",
    "2. What is std for rate?\n",
    "3. What are the high rating and low rating ranges?\n",
    "4. What words are common for high rated wines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot average rate and stanart deviations\n",
    "\n",
    "def show_metric_with_average(metric, series):\n",
    "    \"\"\"\n",
    "    Plot metric values destribution, avg and std\n",
    "    \"\"\"\n",
    "    x, y = _get_value_counts_from_series(\n",
    "        metric, series.fillna(0))\n",
    "    data = py.graph_objs.Scatter(\n",
    "        x=x, y=y, \n",
    "        name='%s distribution' % metric)\n",
    "    # get data to plot avg\n",
    "    avg = series.mean()\n",
    "    avg_trace = py.graph_objs.Scatter(\n",
    "        x=[avg, ] * len(y),\n",
    "        y=y,\n",
    "        mode='markers',\n",
    "        marker={\n",
    "            'color': 'rgb(128, 0, 128)',\n",
    "            'symbol': 'diamond-open',\n",
    "        })\n",
    "    # get data to plot stds\n",
    "    std = series.std()\n",
    "    std_traces = []\n",
    "    MAX_STD_MULTIPLIER = 3\n",
    "    x_y = zip(x, y)\n",
    "    for std_multiplier in\\\n",
    "            xrange(1, MAX_STD_MULTIPLIER + 1):\n",
    "        # filter metric values and frequencies\n",
    "        # where metric is in range \n",
    "        # [avg - std * std_multiplie, avg + std * std_multiplier]\n",
    "        x_y_ = filter(\n",
    "            lambda (x, y): \\\n",
    "                (x >= avg - std * std_multiplier) and\\\n",
    "                (x <= avg + std * std_multiplier),\n",
    "            x_y)\n",
    "        # append scatter plot with filled are in range\n",
    "        std_traces.append(\n",
    "            py.graph_objs.Scatter(\n",
    "                x=[x for x, y in x_y_],\n",
    "                y=[y for x, y in x_y_],\n",
    "                fill='tozeroy')    \n",
    "        )\n",
    "        \n",
    "    layout = py.graph_objs.Layout(title=column)\n",
    "    py.offline.iplot({\n",
    "            'data': [data, avg_trace,] + std_traces, \n",
    "            'layout': layout}) \n",
    "\n",
    "\n",
    "show_metric_with_average('points', wines_df.points)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **high rating** >= 94\n",
    "2. **low rating** <= 83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HIGH_RATING = 94\n",
    "LOW_RATING = 83\n",
    "\n",
    "\n",
    "# Show words for high rating\n",
    "show_most_popular_and_less_popular_words(\n",
    "    wines_df[wines_df.points >= HIGH_RATING]['description_as_bag_of_words'],\n",
    "    'Wines with high rating')\n",
    "\n",
    "# Show words for low rating\n",
    "show_most_popular_and_less_popular_words(\n",
    "    wines_df[wines_df.points <= LOW_RATING]['description_as_bag_of_words'],\n",
    "    'Wines with low rating')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# What words can be found only in one group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_words_in_series(\n",
    "        series, not_include_words_series):\n",
    "    \"\"\"\n",
    "    FIlter words in series, that are not in not_include_words_series\n",
    "    \"\"\"\n",
    "    def _filter_out_words(\n",
    "            bag_of_words, not_include_words_dict):\n",
    "        return filter(\n",
    "            lambda w: w not in not_include_words_dict,\n",
    "            bag_of_words)\n",
    "\n",
    "    from itertools import chain\n",
    "    series = series.copy()\n",
    "    # get dict of not include words\n",
    "    not_include_words_dict = {\n",
    "        word: 1 for word in \n",
    "        chain.from_iterable(\n",
    "            not_include_words_series.tolist())\n",
    "        }\n",
    "    series = series.apply(\n",
    "        lambda b: _filter_out_words(b, not_include_words_dict))\n",
    "    return series\n",
    "\n",
    "# Show most and less popular in high rating wines only\n",
    "show_most_popular_and_less_popular_words(\n",
    "    filter_words_in_series(\n",
    "        wines_df[wines_df.points >= HIGH_RATING]['description_as_bag_of_words'], \n",
    "        wines_df[wines_df.points <= LOW_RATING]['description_as_bag_of_words'],\n",
    "    ),\n",
    "    'Words in high rating wines descriptions only')\n",
    "\n",
    "# Show most and less popular in high rating wines only\n",
    "show_most_popular_and_less_popular_words(\n",
    "    filter_words_in_series(\n",
    "        wines_df[wines_df.points <= LOW_RATING]['description_as_bag_of_words'],\n",
    "        wines_df[wines_df.points >= HIGH_RATING]['description_as_bag_of_words']\n",
    "    ),\n",
    "    'Words in low rating wines descriptions only')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What words can be found in both groups (high and low rating)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_words_in_both_series(\n",
    "        series_1, series_2):\n",
    "    \"\"\"\n",
    "    FIlter words in series, that are in both series\n",
    "    \"\"\"\n",
    "    def _filter_out_words_in_dict(\n",
    "            bag_of_words, include_words_dict):\n",
    "        return filter(\n",
    "            lambda w: w in include_words_dict,\n",
    "            bag_of_words)\n",
    "    \n",
    "    def _generate_word_dict_from_series(\n",
    "            series):\n",
    "        from itertools import chain\n",
    "        return {\n",
    "            word: 1 for word in \n",
    "            chain.from_iterable(\n",
    "                series.tolist())}\n",
    "\n",
    "    series_1 = series_1.copy()\n",
    "    series_2 = series_2.copy()\n",
    "    series_1 = series_1.apply(\n",
    "        lambda b: _filter_out_words_in_dict(\n",
    "                        b, \n",
    "                        _generate_word_dict_from_series(series_2)))\n",
    "    series_2 = series_2.apply(\n",
    "        lambda b: _filter_out_words_in_dict(\n",
    "                        b, \n",
    "                        _generate_word_dict_from_series(series_1)))\n",
    "    return pd.concat([series_2, series_1])\n",
    "                \n",
    "                \n",
    "show_most_popular_and_less_popular_words(\n",
    "    filter_words_in_both_series(\n",
    "        wines_df[wines_df.points >= HIGH_RATING]['description_as_bag_of_words'], \n",
    "        wines_df[wines_df.points <= LOW_RATING]['description_as_bag_of_words'],\n",
    "    ),\n",
    "    'Words both in high rating wines and low rating wines descriptions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What words can be found in all rating groups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_words_that_can_be_found_in_all_ratings(df_):\n",
    "    \"\"\"\n",
    "    Get the list of the words that can be found in description\n",
    "    of all ratings\n",
    "    \"\"\"\n",
    "    from itertools import chain\n",
    "    \n",
    "    dictionary_by_ratings = {}\n",
    "    for rating in df_.points.unique():\n",
    "        dictionary_by_ratings[rating] = \\\n",
    "            set(\n",
    "                chain.from_iterable(\n",
    "                    df_[df_.points == rating]['description_as_bag_of_words'].tolist()))\n",
    "    dictionaries = list(dictionary_by_ratings.values())\n",
    "    result_set = dictionaries[0]\n",
    "    for dictionary in dictionaries[1:]:\n",
    "        result_set = result_set & dictionary\n",
    "    return result_set\n",
    "\n",
    "def filter_descriptions_that_are_common_for_all_ratings(df_):\n",
    "    def _filter_common_words(bag_of_words, common_words_dictionary):\n",
    "        return filter(\n",
    "            lambda w: w in common_words_dictionary,\n",
    "            bag_of_words)\n",
    "\n",
    "    common_words_dictionary = \\\n",
    "        get_words_that_can_be_found_in_all_ratings(df_)\n",
    "    series = df_.description_as_bag_of_words.copy()\n",
    "    return series.apply(\n",
    "        lambda x: _filter_common_words(x, common_words_dictionary))\n",
    "\n",
    "show_most_popular_and_less_popular_words(\n",
    "    filter_descriptions_that_are_common_for_all_ratings(wines_df),\n",
    "    'Wine descriptions that are common to all ratings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What words are the most common for each of the grapes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MIN_LEN_TO_DISPLAY = 0.05 * len(wines_df)\n",
    "for grape in wines_df.variety.unique():\n",
    "    grapes_df = wines_df[wines_df.variety == grape]\n",
    "    if len(grapes_df) < MIN_LEN_TO_DISPLAY:\n",
    "        continue\n",
    "    show_most_popular_and_less_popular_words(\n",
    "        grapes_df.description_as_bag_of_words,\n",
    "        'Grape %s. Total amount of wines %d' % (\n",
    "            grape, len(grapes_df)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is there correlation between price and rating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_correlation_between_metrics(\n",
    "        metric_to_group_by, metric_to_calculate_average, df_):\n",
    "    avg_price_for_points = df_.groupby(\n",
    "            [metric_to_group_by, ])[metric_to_calculate_average].mean().to_frame()\n",
    "\n",
    "    data = py.graph_objs.Scatter(\n",
    "        x=avg_price_for_points.index, \n",
    "        y=avg_price_for_points[metric_to_calculate_average])\n",
    "    layout = py.graph_objs.Layout(\n",
    "        title='Avg %s by %s' % (\n",
    "            metric_to_calculate_average, metric_to_group_by))\n",
    "    py.offline.iplot({\n",
    "            'data': [data], \n",
    "            'layout': layout})  \n",
    "    \n",
    "def plot_correlation_between_price_and_and_rating(df_):\n",
    "    # plot 2 dimensional scatter plot\n",
    "    data = py.graph_objs.Scatter(\n",
    "        x=df_.points, \n",
    "        y=df_.price,\n",
    "        mode='markers')\n",
    "    layout = py.graph_objs.Layout(\n",
    "        title='Dependacnies between price and rating')\n",
    "    py.offline.iplot({\n",
    "            'data': [data], \n",
    "            'layout': layout})\n",
    "                     \n",
    "    # plot average price for rating\n",
    "    plot_correlation_between_metrics(\n",
    "        'points', 'price', df_)\n",
    "    \n",
    "    plot_correlation_between_metrics(\n",
    "        'price', 'points', df_)\n",
    "\n",
    "                     \n",
    "plot_correlation_between_price_and_and_rating(wines_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
